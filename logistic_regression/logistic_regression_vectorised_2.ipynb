{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "This is an implementation of logistic regression. batch gradient descent is used to fit the model paramaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I build a model to address the famous kaggle titanic problem, a binary classification problem. Individuals must be predicted as having survived or not survived the titanic disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max.rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = data[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### impute Age NA values with mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbie.morse/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "feats.Age = feats.Age.fillna(data.Age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare\n",
       "0       3  22.0      1      0   7.2500\n",
       "1       1  38.0      1      0  71.2833\n",
       "2       3  26.0      0      0   7.9250\n",
       "3       1  35.0      1      0  53.1000\n",
       "4       3  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the features x are a n diensional vector:\n",
    "$$x \\in \\mathbb{R}^{n}$$\n",
    "    \n",
    "the weights w are a n dimensional vector\n",
    "$$w \\in \\mathbb{R}^{n}$$\n",
    "z is a linear combination of the weihts an feature values such that:\n",
    "\n",
    "$$z \\in w^{T}x$$\n",
    "    \n",
    "a s the logistic function where:\n",
    "\n",
    "$$y = a(z)$$\n",
    "\n",
    "$$a = \\frac{1}{1+e^{-z}}$$\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(feature_vector, weights):\n",
    "    \n",
    "    '''\n",
    "    takes in vector of feature values and vector of weights and computes output from logistic function\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # calculate 'z'\n",
    "    linear_combination = np.dot(feature_vector, weights)\n",
    "    \n",
    "    # input 'z' into logistic function\n",
    "    function_output = 1 / (1+np.exp(-linear_combination))\n",
    "    \n",
    "    return(function_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fitting the logistic function with batch gradient descent\n",
    "\n",
    "loss function for logistic function is $$ L(w, y) = (-[ylog(y)+(1-y)log(1-y)]$$\n",
    "\n",
    "\n",
    "cost function for logistic function is $$ J(w) = \\frac{1}{m}\\sum_{i=1}^{m} L(w, y)$$\n",
    "\n",
    "\n",
    "In order to minimise the cost function batch gradient descent algorithm is used:\n",
    "\n",
    "$$repeat\\, until\\, convergence$$\n",
    "\n",
    "\n",
    "$$\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\!\\{$$\n",
    "$$w := w - \\alpha\\frac{\\partial{J}}{\\partial{w_j}}$$\n",
    "  $$\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\,\\}$$\n",
    "  \n",
    "  \n",
    "According to the chain rule:\n",
    "\n",
    "\n",
    "$$\\frac{\\partial{L}}{\\partial{w_j}} = \\frac{\\partial{z}}{\\partial{w_j}}*\\frac{\\partial{a}}{\\partial{z}}*\\frac{\\partial{L}}{\\partial{a}}$$\n",
    "\n",
    "\n",
    "which means one can calculate $\\frac{\\partial{L}}{\\partial{w_j}}$ in the following way\n",
    "\n",
    "\n",
    "$$\\frac{\\partial{L}}{\\partial{w_j}} = (a-y)*X_j$$\n",
    "\n",
    "In the below block of code  $\\frac{\\partial{L}}{\\partial{w_j}}$ is represented by the vector 'dw' and $w$ is represented by the vector 'old_params'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(features, y, alpha = 0.05, totalIterations=100):\n",
    "\n",
    "    '''\n",
    "    fits logistic regression model to data with batch gradient descent\n",
    "    \n",
    "    features: pandas dataframe containing features\n",
    "    y: pandas series containing labels\n",
    "    alpha: learning rate\n",
    "    totalIterations: number of iterations of batch gradient descent\n",
    "    \n",
    "    '''\n",
    "\n",
    "    X = np.array(features.T)\n",
    "    X = np.insert(arr = X, values = np.ones(X.shape[1]), obj = 0, axis = 0)\n",
    "    Y = np.array([y]).T\n",
    "################################################################## initialise lists to store loss and cost function values   \n",
    "    loss_function_values = []\n",
    "    cost_function_values =[]\n",
    "################################################################## initialise dictionaries \n",
    "\n",
    "    \n",
    "################################################################## set up arrays\n",
    "    row_number = features.shape[1]+1\n",
    "    old_params = np.zeros((row_number, 1))\n",
    "    new_params = np.zeros((row_number, 1))\n",
    "    dw = np.zeros((row_number, 1))\n",
    "    \n",
    "\n",
    "################################################################## set up arrays\n",
    "\n",
    "\n",
    "################################################################## loop through data \n",
    "    for counter in tqdm(range(totalIterations)):\n",
    "        \n",
    "        #reset dw to zeros\n",
    "        dw = np.zeros(features.shape[1]+1)\n",
    "        #update old paramaters with new paramaters defined from previous iteration\n",
    "        old_params = new_params.copy()\n",
    "        new_params = np.zeros(features.shape[1]+1)\n",
    "        #Create vector Z which holds linear combinations of features for all observations\n",
    "        Z = np.dot(old_params.T, X)\n",
    "        #print(f'dimensions of w is {old_params.shape}')\n",
    "        #print(f'dimensions of X is {X.shape}')\n",
    "        #print(f'dimensions of Z is {Z.shape}')\n",
    "        #create vector A which holds outputs from logistic function for all linear combinations of features in Z\n",
    "        A = 1 / (1+np.exp(-Z.T))\n",
    "        #print(f'dimensions of A is {A.shape}')\n",
    "        #create vector A containing all errors\n",
    "        #print(f'dimensions of Y is {Y.shape}')\n",
    "        E = A - Y\n",
    "\n",
    "################################################################## update dw\n",
    "        #record all average dw values for all features\n",
    "        #print(f'dimensions of E is {E.shape}')\n",
    "        ### got to here\n",
    "        dw = np.dot(E.T,X.T).T\n",
    "        #print(f'dimensions of dw is {dw.shape}')\n",
    "        average_dw = dw/X.shape[1]    \n",
    "        #print(f'average_dw is {average_dw}')\n",
    "################################################################## update dw\n",
    "\n",
    "\n",
    "################################################################## record loss function\n",
    "            \n",
    "        loss_function_outputs = -(Y*(np.log(A))+((1-Y)*np.log(1-A)))\n",
    "        #print(f'dimension of loss_function_outputs is{loss_function_outputs.shape}')\n",
    "        cost_function_output = sum(loss_function_outputs)/X.shape[1]\n",
    "        #print(f'cost_function_output value is {cost_function_output}')\n",
    "        cost_function_values.append(cost_function_output[0])\n",
    "################################################################## record loss function  \n",
    "\n",
    "\n",
    "################################################################## update feature weights\n",
    "        #print(f'dimensions of average_dw is {average_dw.shape}')\n",
    "        #print(f'dimensions of old_params is {old_params.shape} before')\n",
    "        new_params = old_params-alpha*(average_dw)\n",
    "        #print(f'dimensions of new_params is {new_params.shape} after')\n",
    "################################################################## update feature weights\n",
    "\n",
    "    return(new_params, cost_function_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:08<00:00, 1458.68it/s]\n"
     ]
    }
   ],
   "source": [
    "weights, cost_function_outputs = logisticRegression(features = feats, y = data['Survived'], alpha = 0.003, totalIterations=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitted paramater values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model weights are [[ 2.17066313]\n",
      " [-0.80930429]\n",
      " [-0.0331907 ]\n",
      " [-0.2314992 ]\n",
      " [ 0.21131629]\n",
      " [ 0.00611757]]\n"
     ]
    }
   ],
   "source": [
    "print('model weights are {0}'.format(weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot showing output of cost function for each iteration of gradient descent\n",
    "\n",
    "The cost function values decreases for each iteration of gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1f14c470>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = pd.Series(cost_function_outputs) \n",
    "a.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function to predict survival based on feature values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i should vectorise the function that predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, weights, x_cols, sensitivity = 0.5):\n",
    "    \n",
    "    '''\n",
    "    predicts survival using fitted logistic regression model'''\n",
    "    \n",
    "    results = []\n",
    "    for row_number in range(data.shape[0]):\n",
    "\n",
    "        #loops through data and stores the feature vector and label\n",
    "        feature_vector = np.array(list(data.iloc[row_number][x_cols]))\n",
    "        feature_vector = np.insert(feature_vector, obj = [0], values = 1)\n",
    "  \n",
    "    \n",
    "        linear_combination = np.dot(feature_vector, weights)\n",
    "    \n",
    "        function_output = 1 / (1+np.exp(-linear_combination))\n",
    "        \n",
    "        if function_output >= sensitivity:\n",
    "            results.append(1)\n",
    "        else:\n",
    "            results.append(0)\n",
    "        \n",
    "    return(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict using fitted paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict(data, weights, x_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare'], sensitivity=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1Score = f1_score(y_true=data['Survived'], y_pred=results)\n",
    "accuracyScore = accuracy_score(y_true=data['Survived'], y_pred=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a rough measure of goodness of fit as I'm using predictions based off of the training data, this isn't a proper assesment of the model otherwise I would use 10-fold stratified cross-validation. This is simply to check that the model has learned. The model does better than a random sequence of ones and zeros so it was a success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score is 0.5056603773584906\n",
      "accuracy_score is 0.7059483726150393\n"
     ]
    }
   ],
   "source": [
    "print(f'f1_score is {f1Score}')\n",
    "print(f'accuracy_score is {accuracyScore}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the model goodness of fit more iterations of gradient descent should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomLabel = pd.Series(randint(low = 0, high =2, size = data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1ScoreRandom = f1_score(y_true=data['Survived'], y_pred=randomLabel)\n",
    "accuracyScoreRandom = accuracy_score(y_true=data['Survived'], y_pred=randomLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score is 0.43663739021329984\n",
      "accuracy_score is 0.49607182940516276\n"
     ]
    }
   ],
   "source": [
    "print(f'f1_score is {f1ScoreRandom}')\n",
    "print(f'accuracy_score is {accuracyScoreRandom}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
