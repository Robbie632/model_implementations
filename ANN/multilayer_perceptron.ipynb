{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron\n",
    "\n",
    "This is an implementation of a multilayer perceptron. back-propagation is used to fit the model paramaters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I build a model to address the famous kaggle titanic problem, a binary classification problem. Individuals must be predicted as having survived or not survived the titanic disaster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from numpy.random import randint\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max.rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = data[['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### impute Age NA values with mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robbie.morse/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "feats.Age = feats.Age.fillna(data.Age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare\n",
       "0       3  22.0      1      0   7.2500\n",
       "1       1  38.0      1      0  71.2833\n",
       "2       3  26.0      0      0   7.9250\n",
       "3       1  35.0      1      0  53.1000\n",
       "4       3  35.0      0      0   8.0500"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### defining variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be implementing the following artificial neural network (ANN) architecture.\n",
    "\n",
    "The ANN will:\n",
    "\n",
    "* contain 1 hidden layer\n",
    "* contain 6 units in the hidde layer including the bias unit\n",
    "* output will come from a single node\n",
    "* all units will utilise teh sigmoid (logistic) activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"img/mlp.png\" style=\"height:300px\">\n",
    "\n",
    "credit: https://scikit-learn.org/stable/_images/multilayerperceptron_network.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**definitions**\n",
    "<br>\n",
    "each input into the $ith$ layer is as follows\n",
    "$$a^i \\in \\mathbb{R}^{n}$$\n",
    "<br>\n",
    "<br>\n",
    "the weights for teh $ith$ layer are a matrix\n",
    "$$w^i \\in \\mathbb{R}^{mxn}$$\n",
    "<br>\n",
    "<br>\n",
    "The linear combination of variables for the $ith$ layer are \n",
    "$$z^i = w^{i}a^{i-1}$$\n",
    "<br>\n",
    "<br>\n",
    "$\\sigma$ is the logistic function:\n",
    "$$y = \\sigma(z)$$\n",
    "where\n",
    "$$\\sigma(z) = \\frac{1}{1+e^{-z}}$$\n",
    "<br>\n",
    "<br>\n",
    "***\n",
    "**1st layer**\n",
    "<br>\n",
    "the features are an n dimensional vector:\n",
    "$$a^0 \\in \\mathbb{R}^{n}$$\n",
    "<br>\n",
    "\n",
    "***\n",
    "**2st layer**\n",
    "\n",
    "<br>\n",
    "the hidden layer is a n dimensional vector:\n",
    "$$a^1 \\in \\mathbb{R}^{n}$$\n",
    "\n",
    "where n is equal to the number of units including a bias unit\n",
    "    \n",
    "<br>\n",
    "z is a linear combination of the weights and feature values such that:\n",
    "\n",
    "\n",
    "$$z^1 = w^{1}a^0$$\n",
    "\n",
    "$$a^1 = \\sigma(z^1)$$\n",
    "\n",
    "***\n",
    "**output layer**\n",
    "\n",
    "$$a^2 = \\sigma(z^1)$$\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions that need to be made\n",
    "\n",
    "**general**\n",
    "* can be classes\n",
    "* need to use the above notation with correct superscript\n",
    "<br>\n",
    "\n",
    "**functions**\n",
    "* function for making linear combinations (z) that takes in 1 matrix and 1 vector\n",
    "* function for calculating logistic function output that takes in a vector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### function for making linear combinations from 2 matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = multiLayerPerceptron(alpha=5, totalIterations=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi.linearCombination(a=a_1, w=w_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi.sigmoid_activation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.214],\n",
       "       [0.234],\n",
       "       [0.276]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.linear_combination_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.568565299077705"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(1+np.exp(-0.276))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.55329676],\n",
       "       [0.55823452],\n",
       "       [0.5685653 ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi.sigmoid_activation_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2 , 0.22]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_1 = np.array([[0.2,0.22]])\n",
    "a_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3, 0.4, 0.5],\n",
       "       [0.7, 0.7, 0.8]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_1 = np.array([[0.3,0.4,0.5],[0.7,0.7,0.8]])\n",
    "w_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiLayerPerceptron:\n",
    "    def __init__(self, alpha, totalIterations):\n",
    "        self.alpha = alpha\n",
    "        self.totalIterations = totalIterations\n",
    "        \n",
    "    def linearCombination(self, a, w):\n",
    "        self.a = a\n",
    "        self.w = w\n",
    "        \n",
    "        '''\n",
    "        takes in values of units from previous layer (a) and weights(w)\n",
    "        a must have dim = (1, m) and w must have dim = (m, l)\n",
    "        calculates linear combination of variables\n",
    "        outputs vector of dim = (1,l)\n",
    "        '''\n",
    "        \n",
    "        linear_combination = np.dot(a,w).T\n",
    "        self.linear_combination_output = linear_combination\n",
    "        \n",
    "    def sigmoid_activation(self):\n",
    "        sigmoid_activation_output = 1 / (1+np.exp(-self.linear_combination_output))\n",
    "        self.sigmoid_activation_output = sigmoid_activation_output\n",
    "                                         \n",
    "        \n",
    "        \n",
    "        \n",
    "    def sigmoid(self, feature_vector, weights_sig):\n",
    "        self.feature_vector = feature_vector\n",
    "        self.weights_sig = weights_sig\n",
    "    \n",
    "        '''\n",
    "        takes in vector of feature values and vector of weights and computes output from logistic function\n",
    "\n",
    "        '''\n",
    "\n",
    "        # calculate 'z'\n",
    "        linear_combination = np.dot(self.feature_vector, self.weights)\n",
    "\n",
    "        # input 'z' into logistic function\n",
    "        function_output = 1 / (1+np.exp(-linear_combination))\n",
    "\n",
    "        return(function_output)\n",
    "    \n",
    "        \n",
    "    def fit(self, features, y):\n",
    "        self.features = features\n",
    "        self.y = y\n",
    "        \n",
    "        '''\n",
    "        fits logistic regression model to data with batch gradient descent\n",
    "\n",
    "        features: pandas dataframe containing features\n",
    "        y: pandas series containing labels\n",
    "        alpha: learning rate\n",
    "        totalIterations: number of iterations of batch gradient descent\n",
    "\n",
    "        '''\n",
    "\n",
    "        X = np.array(self.features.T)\n",
    "        X = np.insert(arr = X, values = np.ones(X.shape[1]), obj = 0, axis = 0)\n",
    "        Y = np.array([self.y]).T\n",
    "    ################################################################## initialise lists to store loss and cost function values   \n",
    "        loss_function_values = []\n",
    "        cost_function_values =[]\n",
    "    ################################################################## initialise dictionaries \n",
    "\n",
    "\n",
    "    ################################################################## set up arrays\n",
    "        row_number = self.features.shape[1]+1\n",
    "        old_params = np.zeros((row_number, 1))\n",
    "        new_params = np.zeros((row_number, 1))\n",
    "        dw = np.zeros((row_number, 1))\n",
    "\n",
    "\n",
    "    ################################################################## set up arrays\n",
    "\n",
    "\n",
    "    ################################################################## loop through data \n",
    "        for counter in tqdm(range(self.totalIterations)):\n",
    "\n",
    "            #reset dw to zeros\n",
    "            dw = np.zeros(self.features.shape[1]+1)\n",
    "            #update old paramaters with new paramaters defined from previous iteration\n",
    "            old_params = new_params.copy()\n",
    "            new_params = np.zeros(self.features.shape[1]+1)\n",
    "            #Create vector Z which holds linear combinations of features for all observations\n",
    "            Z = np.dot(old_params.T, X)\n",
    "            #print(f'dimensions of w is {old_params.shape}')\n",
    "            #print(f'dimensions of X is {X.shape}')\n",
    "            #print(f'dimensions of Z is {Z.shape}')\n",
    "            #create vector A which holds outputs from logistic function for all linear combinations of features in Z\n",
    "            A = 1 / (1+np.exp(-Z.T))\n",
    "            #print(f'dimensions of A is {A.shape}')\n",
    "            #create vector A containing all errors\n",
    "            #print(f'dimensions of Y is {Y.shape}')\n",
    "            E = A - Y\n",
    "\n",
    "    ################################################################## update dw\n",
    "            #record all average dw values for all features\n",
    "            #print(f'dimensions of E is {E.shape}')\n",
    "            ### got to here\n",
    "            dw = np.dot(E.T,X.T).T\n",
    "            #print(f'dimensions of dw is {dw.shape}')\n",
    "            average_dw = dw/X.shape[1]    \n",
    "            #print(f'average_dw is {average_dw}')\n",
    "    ################################################################## update dw\n",
    "\n",
    "\n",
    "    ################################################################## record loss function\n",
    "\n",
    "            loss_function_outputs = -(Y*(np.log(A))+((1-Y)*np.log(1-A)))\n",
    "            #print(f'dimension of loss_function_outputs is{loss_function_outputs.shape}')\n",
    "            cost_function_output = sum(loss_function_outputs)/X.shape[1]\n",
    "            #print(f'cost_function_output value is {cost_function_output}')\n",
    "            cost_function_values.append(cost_function_output[0])\n",
    "    ################################################################## record loss function  \n",
    "\n",
    "\n",
    "    ################################################################## update feature weights\n",
    "            #print(f'dimensions of average_dw is {average_dw.shape}')\n",
    "            #print(f'dimensions of old_params is {old_params.shape} before')\n",
    "            new_params = old_params-self.alpha*(average_dw)\n",
    "            #print(f'dimensions of new_params is {new_params.shape} after')\n",
    "    ################################################################## update feature weights\n",
    "        self.cost_function_values = cost_function_values\n",
    "        self.fitted_weights = new_params        \n",
    "    \n",
    "    def predict(self, data, weights, x_cols, sensitivity = 0.5):\n",
    "    \n",
    "        '''\n",
    "        predicts survival using fitted logistic regression model\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.weights = weights\n",
    "        self.x_cols = x_cols\n",
    "        self.sensitivity = sensitivity\n",
    "\n",
    "        results = []\n",
    "        X = np.array(self.data[self.x_cols].T)\n",
    "        X = np.insert(arr = X, values = np.ones(X.shape[1]), obj = 0, axis = 0)\n",
    "        \n",
    "        #print(f'dimensions of self.weights.T are {self.weights.T.shape}')\n",
    "        #print(f'dimensions of X are {X.shape}')\n",
    "        linear_combination = np.dot(self.weights.T, X)\n",
    "        \n",
    "        #print(f'the dimensions of linear-combinations.T are {linear_combination.T.shape}')\n",
    "\n",
    "        function_output = 1 / (1+np.exp(-linear_combination))\n",
    "        function_output_list = list(function_output[0])\n",
    "        for i in function_output_list:\n",
    "            if i >= self.sensitivity:\n",
    "                results.append(1)\n",
    "            else:\n",
    "                results.append(0)\n",
    "        \n",
    "\n",
    "        self.results = results\n",
    "        \n",
    "    def plot_cost_function(self):\n",
    "        \n",
    "        '''\n",
    "        plots cost function values as function of batch gradient descent iterations \n",
    "        '''\n",
    "        \n",
    "        values_for_plotting = pd.Series(self.cost_function_values) \n",
    "        values_for_plotting.plot()\n",
    "        \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
